# Q-A-YouTube-Chatbot
ğŸ§  Purpose of the Project:
To analyze the content of a YouTube video by:

Extracting its transcript,

Splitting and embedding the text,

Storing it in a vector store,

Using a language model (LLM) to answer questions based on the video content.

ğŸ”§ Main Components and Steps:
âœ… Step 1: Transcript Extraction
Extracts transcript using YouTubeTranscriptApi.

Tries English first, then falls back to other available languages.

If all fails, uses a sample hardcoded text as a fallback.

âœ… Step 2: Text Splitting
Splits the transcript into manageable chunks using RecursiveCharacterTextSplitter.

This allows the embedding model to better process long text.

âœ… Step 3: Embeddings + Vector Store
Converts text chunks into embeddings using HuggingFaceâ€™s all-MiniLM-L6-v2 model.

Stores those embeddings into FAISS, a vector store.

This makes it possible to search for relevant chunks based on a user's query.

âœ… Step 4: Retrieval
Uses vector similarity to retrieve chunks relevant to the userâ€™s question (e.g., â€œWhat is C++?â€).

âœ… Step 5: Prompt Construction & LLM Response
Constructs a prompt using the retrieved transcript data.

Sends the prompt to a Groq LLM (like llama-3.1-8b-instant) to get a generated answer.

The LLM answers only based on the context provided (RAG principle).

âœ… Step 6: Chain Building
Builds a reusable chain using LangChainâ€™s RunnableParallel and RunnablePassthrough tools.

